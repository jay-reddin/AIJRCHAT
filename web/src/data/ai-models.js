export const aiModels = {
  OpenAI: {
    text: [
      "gpt-5",
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4.1-nano",
      "gpt-4o",
      "gpt-4o-mini",
    ],
    reasoning: ["o1", "o1-mini", "o1-pro", "o3", "o3-mini"],
    vision: ["gpt-4o", "gpt-4.1"],
    image: ["dall-e-3"],
    multimodal: ["gpt-4o", "gpt-4.1"],
    coding: ["gpt-4o", "gpt-4.1", "gpt-5"],
  },
  Claude: {
    text: [
      "claude-sonnet-4",
      "claude-opus-4",
      "claude-3-7-sonnet",
      "claude-3-5-sonnet",
    ],
    vision: ["claude-sonnet-4", "claude-opus-4"],
    multimodal: ["claude-sonnet-4", "claude-opus-4"],
    coding: ["claude-sonnet-4", "claude-opus-4", "claude-3-7-sonnet"],
    thinking: ["claude-3-7-sonnet:thinking"],
  },
  DeepSeek: {
    text: ["deepseek-chat"],
    reasoning: ["deepseek-reasoner"],
    coding: ["deepseek-chat", "deepseek-reasoner"],
  },
  Gemini: {
    text: [
      "google/gemini-2.0-flash-001",
      "google/gemini-2.0-flash-exp:free",
      "google/gemini-2.0-flash-lite-001",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-flash-lite-preview-06-17",
      "google/gemini-2.5-flash-preview",
      "google/gemini-2.5-flash-preview-05-20",
      "google/gemini-2.5-pro",
      "google/gemini-2.5-pro-exp-03-25",
      "google/gemini-2.5-pro-preview",
      "google/gemini-2.5-pro-preview-05-06",
      "google/gemini-flash-1.5",
      "google/gemini-flash-1.5-8b",
      "google/gemini-pro-1.5",
    ],
    thinking: [
      "google/gemini-2.5-flash-preview-05-20:thinking",
      "google/gemini-2.5-flash-preview:thinking",
    ],
    vision: [
      "google/gemini-2.0-flash-001",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro",
    ],
    multimodal: [
      "google/gemini-2.0-flash-001",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro",
    ],
    coding: [
      "google/gemini-2.0-flash-001",
      "google/gemini-2.5-pro",
      "google/gemini-flash-1.5",
    ],
  },
  Llama: {
    text: [
      "meta-llama/llama-3-70b-instruct",
      "meta-llama/llama-3-8b-instruct",
      "meta-llama/llama-3.1-405b",
      "meta-llama/llama-3.1-405b-instruct",
      "meta-llama/llama-3.1-70b-instruct",
      "meta-llama/llama-3.1-8b-instruct",
      "meta-llama/llama-3.2-1b-instruct",
      "meta-llama/llama-3.2-3b-instruct",
      "meta-llama/llama-3.3-70b-instruct",
      "meta-llama/llama-3.3-70b-instruct:free",
      "meta-llama/llama-4-maverick",
      "meta-llama/llama-4-maverick:free",
      "meta-llama/llama-4-scout",
      "meta-llama/llama-4-scout:free",
    ],
    vision: [
      "meta-llama/llama-3.2-11b-vision-instruct",
      "meta-llama/llama-3.2-11b-vision-instruct:free",
      "meta-llama/llama-3.2-90b-vision-instruct",
    ],
    moderation: [
      "meta-llama/llama-guard-2-8b",
      "meta-llama/llama-guard-3-8b",
      "meta-llama/llama-guard-4-12b",
    ],
    coding: [
      "meta-llama/llama-3.1-405b-instruct",
      "meta-llama/llama-3.1-70b-instruct",
      "meta-llama/llama-4-maverick",
    ],
    multimodal: [
      "meta-llama/llama-3.2-90b-vision-instruct",
      "meta-llama/llama-3.2-11b-vision-instruct",
    ],
  },
  Grok: {
    text: ["x-ai/grok-3", "x-ai/grok-4", "x-ai/grok-3-mini"],
    vision: ["x-ai/grok-2-vision-1212", "x-ai/grok-vision-beta"],
    multimodal: ["x-ai/grok-2-vision-1212", "x-ai/grok-vision-beta"],
    coding: ["x-ai/grok-3", "x-ai/grok-4"],
  },
  Mistral: {
    text: [
      "mistral-large-latest",
      "mistral-medium-latest",
      "mistral-small-latest",
      "codestral-latest",
    ],
    coding: ["codestral-latest"],
  },
  Qwen: {
    text: [
      "qwen/qwen-2-72b-instruct",
      "qwen/qwen-2.5-72b-instruct",
      "qwen/qwen-2.5-72b-instruct:free",
      "qwen/qwen-2.5-7b-instruct",
      "qwen/qwen-max",
      "qwen/qwen-plus",
      "qwen/qwen-turbo",
      "qwen/qwen3-14b",
      "qwen/qwen3-14b:free",
      "qwen/qwen3-235b-a22b",
      "qwen/qwen3-235b-a22b-07-25",
      "qwen/qwen3-235b-a22b-07-25:free",
      "qwen/qwen3-235b-a22b:free",
      "qwen/qwen3-30b-a3b",
      "qwen/qwen3-30b-a3b:free",
      "qwen/qwen3-32b",
      "qwen/qwen3-4b:free",
      "qwen/qwen3-8b",
      "qwen/qwen3-8b:free",
      "qwen/qwq-32b",
      "qwen/qwq-32b-preview",
      "qwen/qwq-32b:free",
    ],
    coding: [
      "qwen/qwen-2.5-coder-32b-instruct",
      "qwen/qwen-2.5-coder-32b-instruct:free",
      "qwen/qwen3-coder",
    ],
    vision: [
      "qwen/qwen-2.5-vl-7b-instruct",
      "qwen/qwen-vl-max",
      "qwen/qwen-vl-plus",
      "qwen/qwen2.5-vl-32b-instruct",
      "qwen/qwen2.5-vl-32b-instruct:free",
      "qwen/qwen2.5-vl-72b-instruct",
      "qwen/qwen2.5-vl-72b-instruct:free",
    ],
    multimodal: [
      "qwen/qwen-vl-max",
      "qwen/qwen-vl-plus",
      "qwen/qwen2.5-vl-72b-instruct",
    ],
  },
};

// OpenRouter Models
export const openRouterModels = [
  "openrouter:01-ai/yi-large",
  "openrouter:aetherwiing/mn-starcannon-12b",
  "openrouter:agentica-org/deepcoder-14b-preview:free",
  "openrouter:ai21/jamba-1.6-large",
  "openrouter:ai21/jamba-1.6-mini",
  "openrouter:aion-labs/aion-1.0",
  "openrouter:aion-labs/aion-1.0-mini",
  "openrouter:aion-labs/aion-rp-llama-3.1-8b",
  "openrouter:alfredpros/codellama-7b-instruct-solidity",
  "openrouter:alpindale/goliath-120b",
  "openrouter:alpindale/magnum-72b",
  "openrouter:amazon/nova-lite-v1",
  "openrouter:amazon/nova-micro-v1",
  "openrouter:amazon/nova-pro-v1",
  "openrouter:anthracite-org/magnum-v2-72b",
  "openrouter:anthracite-org/magnum-v4-72b",
  "openrouter:anthropic/claude-2",
  "openrouter:anthropic/claude-2.0",
  "openrouter:anthropic/claude-2.0:beta",
  "openrouter:anthropic/claude-2.1",
  "openrouter:anthropic/claude-2.1:beta",
  "openrouter:anthropic/claude-2:beta",
  "openrouter:anthropic/claude-3-haiku",
  "openrouter:anthropic/claude-3-haiku:beta",
  "openrouter:anthropic/claude-3-opus",
  "openrouter:anthropic/claude-3-opus:beta",
  "openrouter:anthropic/claude-3-sonnet",
  "openrouter:anthropic/claude-3-sonnet:beta",
  "openrouter:anthropic/claude-3.5-haiku",
  "openrouter:anthropic/claude-3.5-haiku-20241022",
  "openrouter:anthropic/claude-3.5-haiku-20241022:beta",
  "openrouter:anthropic/claude-3.5-haiku:beta",
  "openrouter:anthropic/claude-3.5-sonnet",
  "openrouter:anthropic/claude-3.5-sonnet-20240620",
  "openrouter:anthropic/claude-3.5-sonnet-20240620:beta",
  "openrouter:anthropic/claude-3.5-sonnet:beta",
  "openrouter:anthropic/claude-3.7-sonnet",
  "openrouter:anthropic/claude-3.7-sonnet:beta",
  "openrouter:anthropic/claude-3.7-sonnet:thinking",
  "openrouter:anthropic/claude-opus-4",
  "openrouter:anthropic/claude-sonnet-4",
  "openrouter:arcee-ai/arcee-blitz",
  "openrouter:arcee-ai/caller-large",
  "openrouter:arcee-ai/coder-large",
  "openrouter:arcee-ai/maestro-reasoning",
  "openrouter:arcee-ai/spotlight",
  "openrouter:arcee-ai/virtuoso-large",
  "openrouter:arcee-ai/virtuoso-medium-v2",
  "openrouter:arliai/qwq-32b-arliai-rpr-v1:free",
  "openrouter:baidu/ernie-4.5-300b-a47b",
  "openrouter:cognitivecomputations/dolphin-mixtral-8x22b",
  "openrouter:cognitivecomputations/dolphin3.0-mistral-24b:free",
  "openrouter:cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
  "openrouter:cohere/command",
  "openrouter:cohere/command-a",
  "openrouter:cohere/command-r",
  "openrouter:cohere/command-r-03-2024",
  "openrouter:cohere/command-r-08-2024",
  "openrouter:cohere/command-r-plus",
  "openrouter:cohere/command-r-plus-04-2024",
  "openrouter:cohere/command-r-plus-08-2024",
  "openrouter:cohere/command-r7b-12-2024",
  "openrouter:deepseek/deepseek-chat",
  "openrouter:deepseek/deepseek-chat-v3-0324",
  "openrouter:deepseek/deepseek-chat-v3-0324:free",
  "openrouter:deepseek/deepseek-chat:free",
  "openrouter:deepseek/deepseek-prover-v2",
  "openrouter:deepseek/deepseek-r1",
  "openrouter:deepseek/deepseek-r1-0528",
  "openrouter:deepseek/deepseek-r1-0528-qwen3-8b",
  "openrouter:deepseek/deepseek-r1-0528-qwen3-8b:free",
  "openrouter:deepseek/deepseek-r1-0528:free",
  "openrouter:deepseek/deepseek-r1-distill-llama-70b",
  "openrouter:deepseek/deepseek-r1-distill-llama-70b:free",
  "openrouter:deepseek/deepseek-r1-distill-llama-8b",
  "openrouter:deepseek/deepseek-r1-distill-qwen-1.5b",
  "openrouter:deepseek/deepseek-r1-distill-qwen-14b",
  "openrouter:deepseek/deepseek-r1-distill-qwen-14b:free",
  "openrouter:deepseek/deepseek-r1-distill-qwen-32b",
  "openrouter:deepseek/deepseek-r1-distill-qwen-7b",
  "openrouter:deepseek/deepseek-r1:free",
  "openrouter:deepseek/deepseek-v3-base:free",
  "openrouter:eleutherai/llemma_7b",
  "openrouter:eva-unit-01/eva-llama-3.33-70b",
  "openrouter:eva-unit-01/eva-qwen-2.5-72b",
  "openrouter:featherless/qwerky-72b:free",
  "openrouter:google/gemini-2.0-flash-001",
  "openrouter:google/gemini-2.0-flash-exp:free",
  "openrouter:google/gemini-2.0-flash-lite-001",
  "openrouter:google/gemini-2.5-flash",
  "openrouter:google/gemini-2.5-flash-lite-preview-06-17",
  "openrouter:google/gemini-2.5-flash-preview",
  "openrouter:google/gemini-2.5-flash-preview-05-20",
  "openrouter:google/gemini-2.5-flash-preview-05-20:thinking",
  "openrouter:google/gemini-2.5-flash-preview:thinking",
  "openrouter:google/gemini-2.5-pro",
  "openrouter:google/gemini-2.5-pro-exp-03-25",
  "openrouter:google/gemini-2.5-pro-preview",
  "openrouter:google/gemini-2.5-pro-preview-05-06",
  "openrouter:google/gemini-flash-1.5",
  "openrouter:google/gemini-flash-1.5-8b",
  "openrouter:google/gemini-pro-1.5",
  "openrouter:google/gemma-2-27b-it",
  "openrouter:google/gemma-2-9b-it",
  "openrouter:google/gemma-2-9b-it:free",
  "openrouter:google/gemma-3-12b-it",
  "openrouter:google/gemma-3-12b-it:free",
  "openrouter:google/gemma-3-27b-it",
  "openrouter:google/gemma-3-27b-it:free",
  "openrouter:google/gemma-3-4b-it",
  "openrouter:google/gemma-3-4b-it:free",
  "openrouter:google/gemma-3n-e4b-it",
  "openrouter:google/gemma-3n-e4b-it:free",
  "openrouter:gryphe/mythomax-l2-13b",
  "openrouter:inception/mercury",
  "openrouter:inception/mercury-coder",
  "openrouter:infermatic/mn-inferor-12b",
  "openrouter:inflection/inflection-3-pi",
  "openrouter:inflection/inflection-3-productivity",
  "openrouter:liquid/lfm-3b",
  "openrouter:liquid/lfm-40b",
  "openrouter:liquid/lfm-7b",
  "openrouter:mancer/weaver",
  "openrouter:meta-llama/llama-3-70b-instruct",
  "openrouter:meta-llama/llama-3-8b-instruct",
  "openrouter:meta-llama/llama-3.1-405b",
  "openrouter:meta-llama/llama-3.1-405b-instruct",
  "openrouter:meta-llama/llama-3.1-70b-instruct",
  "openrouter:meta-llama/llama-3.1-8b-instruct",
  "openrouter:meta-llama/llama-3.2-11b-vision-instruct",
  "openrouter:meta-llama/llama-3.2-11b-vision-instruct:free",
  "openrouter:meta-llama/llama-3.2-1b-instruct",
  "openrouter:meta-llama/llama-3.2-3b-instruct",
  "openrouter:meta-llama/llama-3.2-90b-vision-instruct",
  "openrouter:meta-llama/llama-3.3-70b-instruct",
  "openrouter:meta-llama/llama-3.3-70b-instruct:free",
  "openrouter:meta-llama/llama-4-maverick",
  "openrouter:meta-llama/llama-4-maverick:free",
  "openrouter:meta-llama/llama-4-scout",
  "openrouter:meta-llama/llama-4-scout:free",
  "openrouter:meta-llama/llama-guard-2-8b",
  "openrouter:meta-llama/llama-guard-3-8b",
  "openrouter:meta-llama/llama-guard-4-12b",
  "openrouter:microsoft/mai-ds-r1:free",
  "openrouter:microsoft/phi-3-medium-128k-instruct",
  "openrouter:microsoft/phi-3-mini-128k-instruct",
  "openrouter:microsoft/phi-3.5-mini-128k-instruct",
  "openrouter:microsoft/phi-4",
  "openrouter:microsoft/phi-4-multimodal-instruct",
  "openrouter:microsoft/phi-4-reasoning-plus",
  "openrouter:microsoft/wizardlm-2-8x22b",
  "openrouter:minimax/minimax-01",
  "openrouter:minimax/minimax-m1",
  "openrouter:mistralai/codestral-2501",
  "openrouter:mistralai/devstral-small",
  "openrouter:mistralai/devstral-small:free",
  "openrouter:mistralai/magistral-medium-2506",
  "openrouter:mistralai/magistral-medium-2506:thinking",
  "openrouter:mistralai/magistral-small-2506",
  "openrouter:mistralai/ministral-3b",
  "openrouter:mistralai/ministral-8b",
  "openrouter:mistralai/mistral-7b-instruct",
  "openrouter:mistralai/mistral-7b-instruct-v0.1",
  "openrouter:mistralai/mistral-7b-instruct-v0.2",
  "openrouter:mistralai/mistral-7b-instruct-v0.3",
  "openrouter:mistralai/mistral-7b-instruct:free",
  "openrouter:mistralai/mistral-large",
  "openrouter:mistralai/mistral-large-2407",
  "openrouter:mistralai/mistral-large-2411",
  "openrouter:mistralai/mistral-medium-3",
  "openrouter:mistralai/mistral-nemo",
  "openrouter:mistralai/mistral-nemo:free",
  "openrouter:mistralai/mistral-saba",
  "openrouter:mistralai/mistral-small",
  "openrouter:mistralai/mistral-small-24b-instruct-2501",
  "openrouter:mistralai/mistral-small-24b-instruct-2501:free",
  "openrouter:mistralai/mistral-small-3.1-24b-instruct",
  "openrouter:mistralai/mistral-small-3.1-24b-instruct:free",
  "openrouter:mistralai/mistral-small-3.2-24b-instruct",
  "openrouter:mistralai/mistral-small-3.2-24b-instruct:free",
  "openrouter:mistralai/mistral-tiny",
  "openrouter:mistralai/mixtral-8x22b-instruct",
  "openrouter:mistralai/mixtral-8x7b-instruct",
  "openrouter:mistralai/pixtral-12b",
  "openrouter:mistralai/pixtral-large-2411",
  "openrouter:moonshotai/kimi-dev-72b:free",
  "openrouter:moonshotai/kimi-vl-a3b-thinking:free",
  "openrouter:morph/morph-v2",
  "openrouter:morph/morph-v3-fast",
  "openrouter:morph/morph-v3-large",
  "openrouter:neversleep/llama-3-lumimaid-70b",
  "openrouter:neversleep/llama-3-lumimaid-8b",
  "openrouter:neversleep/llama-3.1-lumimaid-8b",
  "openrouter:neversleep/noromaid-20b",
  "openrouter:nothingiisreal/mn-celeste-12b",
  "openrouter:nousresearch/deephermes-3-llama-3-8b-preview:free",
  "openrouter:nousresearch/hermes-2-pro-llama-3-8b",
  "openrouter:nousresearch/hermes-3-llama-3.1-405b",
  "openrouter:nousresearch/hermes-3-llama-3.1-70b",
  "openrouter:nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
  "openrouter:nvidia/llama-3.1-nemotron-70b-instruct",
  "openrouter:nvidia/llama-3.1-nemotron-ultra-253b-v1",
  "openrouter:nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
  "openrouter:nvidia/llama-3.3-nemotron-super-49b-v1",
  "openrouter:nvidia/llama-3.3-nemotron-super-49b-v1:free",
  "openrouter:openai/chatgpt-4o-latest",
  "openrouter:openai/codex-mini",
  "openrouter:openai/gpt-3.5-turbo-0613",
  "openrouter:openai/gpt-3.5-turbo-16k",
  "openrouter:openai/gpt-3.5-turbo-instruct",
  "openrouter:openai/gpt-4",
  "openrouter:openai/gpt-4-0314",
  "openrouter:openai/gpt-4-1106-preview",
  "openrouter:openai/gpt-4-turbo",
  "openrouter:openai/gpt-4-turbo-preview",
  "openrouter:openai/gpt-4.1",
  "openrouter:openai/gpt-4.1-mini",
  "openrouter:openai/gpt-4.1-nano",
  "openrouter:openai/gpt-4.5-preview",
  "openrouter:openai/gpt-4o",
  "openrouter:openai/gpt-4o-2024-05-13",
  "openrouter:openai/gpt-4o-2024-08-06",
  "openrouter:openai/gpt-4o-2024-11-20",
  "openrouter:openai/gpt-4o-mini",
  "openrouter:openai/gpt-4o-mini-2024-07-18",
  "openrouter:openai/gpt-4o-mini-search-preview",
  "openrouter:openai/gpt-4o-search-preview",
  "openrouter:openai/gpt-4o:extended",
  "openrouter:openai/o1",
  "openrouter:openai/o1-mini",
  "openrouter:openai/o1-mini-2024-09-12",
  "openrouter:openai/o1-preview",
  "openrouter:openai/o1-preview-2024-09-12",
  "openrouter:openai/o1-pro",
  "openrouter:openai/o3",
  "openrouter:openai/o3-mini",
  "openrouter:openai/o3-mini-high",
  "openrouter:openai/o3-pro",
  "openrouter:openai/o4-mini",
  "openrouter:openai/o4-mini-high",
  "openrouter:opengvlab/internvl3-14b",
  "openrouter:openrouter/auto",
  "openrouter:openrouter/cypher-alpha:free",
  "openrouter:perplexity/r1-1776",
  "openrouter:perplexity/sonar",
  "openrouter:perplexity/sonar-deep-research",
  "openrouter:perplexity/sonar-pro",
  "openrouter:perplexity/sonar-reasoning",
  "openrouter:perplexity/sonar-reasoning-pro",
  "openrouter:pygmalionai/mythalion-13b",
  "openrouter:qwen/qwen-2-72b-instruct",
  "openrouter:qwen/qwen-2.5-72b-instruct",
  "openrouter:qwen/qwen-2.5-72b-instruct:free",
  "openrouter:qwen/qwen-2.5-7b-instruct",
  "openrouter:qwen/qwen-2.5-coder-32b-instruct",
  "openrouter:qwen/qwen-2.5-coder-32b-instruct:free",
  "openrouter:qwen/qwen-2.5-vl-7b-instruct",
  "openrouter:qwen/qwen-max",
  "openrouter:qwen/qwen-plus",
  "openrouter:qwen/qwen-turbo",
  "openrouter:qwen/qwen-vl-max",
  "openrouter:qwen/qwen-vl-plus",
  "openrouter:qwen/qwen2.5-vl-32b-instruct",
  "openrouter:qwen/qwen2.5-vl-32b-instruct:free",
  "openrouter:qwen/qwen2.5-vl-72b-instruct",
  "openrouter:qwen/qwen2.5-vl-72b-instruct:free",
  "openrouter:qwen/qwen3-14b",
  "openrouter:qwen/qwen3-14b:free",
  "openrouter:qwen/qwen3-235b-a22b",
  "openrouter:qwen/qwen3-235b-a22b:free",
  "openrouter:qwen/qwen3-30b-a3b",
  "openrouter:qwen/qwen3-30b-a3b:free",
  "openrouter:qwen/qwen3-32b",
  "openrouter:qwen/qwen3-32b:free",
  "openrouter:qwen/qwen3-8b",
  "openrouter:qwen/qwen3-8b:free",
  "openrouter:qwen/qwq-32b",
  "openrouter:qwen/qwq-32b-preview",
  "openrouter:qwen/qwq-32b:free",
  "openrouter:raifle/sorcererlm-8x22b",
  "openrouter:rekaai/reka-flash-3:free",
  "openrouter:sao10k/fimbulvetr-11b-v2",
  "openrouter:sao10k/l3-euryale-70b",
  "openrouter:sao10k/l3-lunaris-8b",
  "openrouter:sao10k/l3.1-euryale-70b",
  "openrouter:sao10k/l3.3-euryale-70b",
  "openrouter:sarvamai/sarvam-m:free",
  "openrouter:scb10x/llama3.1-typhoon2-70b-instruct",
  "openrouter:shisa-ai/shisa-v2-llama3.3-70b:free",
  "openrouter:sophosympatheia/midnight-rose-70b",
  "openrouter:thedrummer/anubis-70b-v1.1",
  "openrouter:thedrummer/anubis-pro-105b-v1",
  "openrouter:thedrummer/rocinante-12b",
  "openrouter:thedrummer/skyfall-36b-v2",
  "openrouter:thedrummer/unslopnemo-12b",
  "openrouter:thedrummer/valkyrie-49b-v1",
  "openrouter:thudm/glm-4-32b",
  "openrouter:thudm/glm-4-32b:free",
  "openrouter:thudm/glm-z1-32b:free",
  "openrouter:tngtech/deepseek-r1t-chimera:free",
  "openrouter:undi95/remm-slerp-l2-13b",
  "openrouter:undi95/toppy-m-7b",
  "openrouter:x-ai/grok-2-1212",
  "openrouter:x-ai/grok-2-vision-1212",
  "openrouter:x-ai/grok-3",
  "openrouter:x-ai/grok-3-beta",
  "openrouter:x-ai/grok-3-mini",
  "openrouter:x-ai/grok-3-mini-beta",
  "openrouter:x-ai/grok-vision-beta",
];

// Model capabilities and features
export const modelCapabilities = {
  // OpenAI Models
  "gpt-5": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: true,
    reasoning: false,
    multimodal: false,
    coding: true,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description:
      "Most advanced GPT model with enhanced reasoning and coding capabilities",
    strengths: [
      "General tasks",
      "Code generation",
      "Creative writing",
      "Complex reasoning",
    ],
  },
  "gpt-4.1": {
    functions: true,
    streaming: true,
    vision: true,
    imageGeneration: false,
    reasoning: false,
    multimodal: true,
    coding: true,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description: "Advanced GPT model with vision and multimodal capabilities",
    strengths: [
      "Vision analysis",
      "Complex reasoning",
      "Multimodal tasks",
      "Code generation",
    ],
  },
  "gpt-4.1-mini": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: false,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description: "Faster, cost-effective version of GPT-4.1",
    strengths: ["Speed", "Efficiency", "General tasks", "Cost-effective"],
  },
  "gpt-4o": {
    functions: true,
    streaming: true,
    vision: true,
    imageGeneration: false,
    reasoning: false,
    multimodal: true,
    coding: true,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description: "Omni-modal GPT with vision and audio capabilities",
    strengths: [
      "Vision analysis",
      "Multimodal understanding",
      "Real-time tasks",
      "Code generation",
    ],
  },
  "gpt-4o-mini": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: false,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description: "Lightweight version of GPT-4o",
    strengths: ["Speed", "Cost efficiency", "Simple tasks"],
  },
  o1: {
    functions: false,
    streaming: false,
    vision: false,
    imageGeneration: false,
    reasoning: true,
    multimodal: false,
    coding: false,
    thinking: false,
    maxTokens: 200000,
    contextWindow: 200000,
    description: "Advanced reasoning model for complex problems",
    strengths: ["Complex reasoning", "Mathematics", "Science", "Analysis"],
  },
  "o1-mini": {
    functions: false,
    streaming: false,
    vision: false,
    imageGeneration: false,
    reasoning: true,
    multimodal: false,
    coding: false,
    thinking: false,
    maxTokens: 65536,
    contextWindow: 65536,
    description: "Compact reasoning model",
    strengths: ["Logic problems", "Code debugging", "Math"],
  },
  o3: {
    functions: false,
    streaming: false,
    vision: false,
    imageGeneration: false,
    reasoning: true,
    multimodal: false,
    coding: false,
    thinking: false,
    maxTokens: 200000,
    contextWindow: 200000,
    description: "Latest reasoning model with enhanced capabilities",
    strengths: ["Advanced reasoning", "Complex analysis", "Research tasks"],
  },
  "o3-mini": {
    functions: false,
    streaming: false,
    vision: false,
    imageGeneration: false,
    reasoning: true,
    multimodal: false,
    coding: false,
    thinking: false,
    maxTokens: 65536,
    contextWindow: 65536,
    description: "Efficient reasoning model",
    strengths: ["Quick reasoning", "Problem solving", "Analysis"],
  },

  // Claude Models
  "claude-sonnet-4": {
    functions: true,
    streaming: true,
    vision: true,
    imageGeneration: false,
    reasoning: false,
    multimodal: true,
    coding: true,
    thinking: false,
    maxTokens: 200000,
    contextWindow: 200000,
    description:
      "Balanced intelligence, speed, and cost with vision capabilities",
    strengths: [
      "Writing",
      "Analysis",
      "Code generation",
      "Vision",
      "Multimodal tasks",
    ],
  },
  "claude-opus-4": {
    functions: true,
    streaming: true,
    vision: true,
    imageGeneration: false,
    reasoning: false,
    multimodal: true,
    coding: true,
    thinking: false,
    maxTokens: 200000,
    contextWindow: 200000,
    description: "Most intelligent Claude model with advanced capabilities",
    strengths: [
      "Complex reasoning",
      "Creative writing",
      "Research",
      "Code generation",
    ],
  },
  "claude-3-7-sonnet": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: true,
    thinking: false,
    maxTokens: 200000,
    contextWindow: 200000,
    description: "High-performance Claude model with coding expertise",
    strengths: ["Writing", "Analysis", "Code generation", "Problem solving"],
  },
  "claude-3-7-sonnet:thinking": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: true,
    thinking: true,
    maxTokens: 200000,
    contextWindow: 200000,
    description: "Claude with enhanced thinking and reasoning capabilities",
    strengths: [
      "Step-by-step reasoning",
      "Complex analysis",
      "Detailed explanations",
    ],
  },

  // DeepSeek Models
  "deepseek-chat": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: true,
    thinking: false,
    maxTokens: 64000,
    contextWindow: 64000,
    description: "DeepSeek V3 - Open-source model with strong performance",
    strengths: [
      "Code generation",
      "Mathematics",
      "Open source",
      "Multilingual",
    ],
  },
  "deepseek-reasoner": {
    functions: false,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: true,
    multimodal: false,
    coding: true,
    thinking: false,
    maxTokens: 64000,
    contextWindow: 64000,
    description:
      "DeepSeek R1 - Specialized reasoning model for complex problems",
    strengths: [
      "Step-by-step reasoning",
      "Problem solving",
      "Analysis",
      "Chain-of-thought",
    ],
  },

  // Grok Models
  "x-ai/grok-4": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: true,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description: "Witty and engaging AI with real-time knowledge",
    strengths: ["Humor", "Current events", "Creative responses", "Personality"],
  },

  // Gemini Models
  "google/gemini-2.0-flash-001": {
    functions: true,
    streaming: true,
    vision: true,
    imageGeneration: false,
    reasoning: false,
    multimodal: true,
    coding: true,
    thinking: false,
    maxTokens: 1048576,
    contextWindow: 1048576,
    description: "Google's fastest multimodal model with massive context",
    strengths: ["Speed", "Vision", "Large context", "Multimodal"],
  },
  "google/gemini-2.5-pro": {
    functions: true,
    streaming: true,
    vision: true,
    imageGeneration: false,
    reasoning: false,
    multimodal: true,
    coding: true,
    thinking: false,
    maxTokens: 2097152,
    contextWindow: 2097152,
    description: "Google's most capable model with 2M+ token context",
    strengths: ["Complex reasoning", "Massive context", "Analysis", "Research"],
  },

  // Meta Llama Models
  "meta-llama/llama-4-maverick": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: true,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description: "Meta's advanced Llama 4 model",
    strengths: ["Open source", "Code generation", "Versatility", "Performance"],
  },
  "meta-llama/llama-3.2-90b-vision-instruct": {
    functions: true,
    streaming: true,
    vision: true,
    imageGeneration: false,
    reasoning: false,
    multimodal: true,
    coding: false,
    thinking: false,
    maxTokens: 128000,
    contextWindow: 128000,
    description: "Llama with advanced vision capabilities",
    strengths: ["Vision analysis", "Open source", "Multimodal", "Large model"],
  },

  // Qwen Models
  "qwen/qwen3-235b-a22b": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: false,
    thinking: false,
    maxTokens: 32000,
    contextWindow: 32000,
    description: "Massive 235B parameter Chinese AI model",
    strengths: [
      "Multilingual",
      "Code generation",
      "Mathematics",
      "Large scale",
    ],
  },
  "qwen/qwen3-coder": {
    functions: true,
    streaming: true,
    vision: false,
    imageGeneration: false,
    reasoning: false,
    multimodal: false,
    coding: true,
    thinking: false,
    maxTokens: 32000,
    contextWindow: 32000,
    description: "Specialized coding model from Qwen",
    strengths: [
      "Code generation",
      "Programming",
      "Software development",
      "Multiple languages",
    ],
  },
};

// Helper function to get model capabilities
export const getModelCapabilities = (modelId) => {
  return (
    modelCapabilities[modelId] || {
      functions: true,
      streaming: true,
      vision: false,
      imageGeneration: false,
      reasoning: false,
      multimodal: false,
      coding: false,
      thinking: false,
      maxTokens: 4096,
      contextWindow: 4096,
      description: "Standard AI model",
      strengths: ["General tasks"],
    }
  );
};

// Helper function to check if model supports a specific feature
export const modelSupports = (modelId, feature) => {
  const capabilities = getModelCapabilities(modelId);
  return capabilities[feature] || false;
};

// Helper function to get model display name
export const getModelDisplayName = (modelId) => {
  // Remove provider prefix for cleaner display
  if (modelId.startsWith("openrouter:")) {
    const cleanId = modelId.replace("openrouter:", "");
    const parts = cleanId.split("/");
    if (parts.length > 1) {
      return parts[parts.length - 1];
    }
    return cleanId;
  }

  if (modelId.includes("/")) {
    const parts = modelId.split("/");
    return parts[parts.length - 1];
  }

  return modelId;
};

// Helper function to get unique models (remove duplicates)
export const getUniqueModels = (models) => {
  const seen = new Set();
  return models.filter((model) => {
    if (seen.has(model)) {
      return false;
    }
    seen.add(model);
    return true;
  });
};

// Get all available models
export const getAllModels = () => {
  const standardModels = Object.values(aiModels).flatMap((provider) =>
    Object.values(provider).flat(),
  );
  return getUniqueModels([...standardModels, ...openRouterModels]);
};

export const defaultModels = [
  "gpt-5",
  "gpt-4.1",
  "gpt-4o",
  "claude-sonnet-4",
  "google/gemini-2.0-flash-001",
  "google/gemini-2.5-pro",
  "qwen/qwen3-235b-a22b",
  "qwen/qwen3-coder",
  "meta-llama/llama-4-maverick",
  "meta-llama/llama-3.2-90b-vision-instruct",
  "deepseek-chat",
  "deepseek-reasoner",
  "x-ai/grok-4",
];
